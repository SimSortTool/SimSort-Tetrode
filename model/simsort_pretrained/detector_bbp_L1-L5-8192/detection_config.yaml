dmodel_arch: transformer
dropout: 0.2
hidden_size: 256
input_size: 4
learning_rate: 0.0005
nhead: 4
num_layers: 4
output_size: 1
weight_decay: 1.0e-05
